## Project Title

GBDA302 Side quest 2 - Panic Blob: Emotional Movement and Mischief Interaction

---

## Group Number (only for group work)

N/A — Individual Side Quest

---

## Description

This project features a soft, animated blob that expresses panic through movement, deformation, and interaction with its environment.

On screen, the user sees a small enclosed map containing a jittery blue blob and scattered objects. When the mouse cursor approaches, the blob reacts as if the cursor is a threat: it flees, shakes, and becomes more visually unstable. As it moves around the space, the blob can bump into objects, pushing them away. Smaller objects may be temporarily “stolen” and orbit the blob before eventually falling back into the environment.

The design is inspired by the idea that emotion can be communicated through behavior and motion, rather than facial detail or narrative alone. The project explores how panic can be made readable through exaggerated physics, constrained space, and disruptive interactions.

---

## Interaction Instructions

- Open the sketch in a browser (via GitHub Pages or a local server).
- Move your mouse cursor around the canvas.
- When the cursor gets close to the blob, it will panic and flee.
- Guide the blob into objects to bump them around.
- Smaller objects may be temporarily stolen and orbit the blob before dropping back into the scene.
- Refresh the page to reset the environment.

Visual feedback to watch for:

- Increased shaking and faster “breathing” when the blob is panicking
- Eyes and mouth changing to reflect fear
- Objects reacting physically when collided with

---

## Assets

This project does not use external image, sound, or media assets.  
All visuals are generated procedurally using p5.js.

## GenAI

GenAI (ChatGPT) was used as coding support during development. It assisted with rewriting and extending existing p5.js code, restructuring functions, suggesting parameter adjustments, and improving code comments for clarity and consistency.

GenAI did not define the project concept, emotional intent, or interaction goals. All design decisions—such as how panic should be expressed, when behaviors felt unreadable, and how interactions were balanced—were made through manual testing and observation. GenAI-generated code was treated as a draft or reference and was frequently modified, simplified, or rejected based on observed behavior.

---
